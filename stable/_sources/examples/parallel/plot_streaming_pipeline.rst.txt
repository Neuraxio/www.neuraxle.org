.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_examples_parallel_plot_streaming_pipeline.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_parallel_plot_streaming_pipeline.py:


Parallel processing in Neuraxle
===================================================================

This demonstrates how to stream data in parallel in a Neuraxle pipeline.

..
    Copyright 2019, Neuraxio Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.



.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    SequentialQueuedPipeline
    execution time: 0.4587130546569824 seconds
    VanillaPipeline
    execution time: 2.0222725868225098 seconds




|


.. code-block:: default

    import time
    import numpy as np

    from neuraxle.distributed.streaming import SequentialQueuedPipeline
    from neuraxle.pipeline import Pipeline
    from neuraxle.steps.loop import ForEachDataInput
    from neuraxle.steps.misc import Sleep
    from neuraxle.steps.numpy import MultiplyByN


    def main():
        """
        Process tasks of batch size 10 with 8 queued workers that have a max queue size of 10.
        Each task doest the following: For each data input, sleep 0.02 seconds, and multiply by 2.
        """
        sleep_time = 0.02
        p = SequentialQueuedPipeline([
            Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]),
        ], n_workers_per_step=8, max_queue_size=10, batch_size=10)

        a = time.time()
        outputs_streaming = p.transform(list(range(100)))
        b = time.time()
        time_queued_pipeline = b - a
        print('SequentialQueuedPipeline')
        print('execution time: {} seconds'.format(time_queued_pipeline))

        """
        Process data inputs sequentially. 
        For each data input, sleep 0.02 seconds, and then multiply by 2.
        """
        p = Pipeline([
            Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]),
        ])

        a = time.time()
        outputs_vanilla = p.transform(list(range(100)))
        b = time.time()
        time_vanilla_pipeline = b - a

        print('VanillaPipeline')
        print('execution time: {} seconds'.format(time_vanilla_pipeline))

        assert time_queued_pipeline < time_vanilla_pipeline
        assert np.array_equal(outputs_streaming, outputs_vanilla)


    if __name__ == '__main__':
        main()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  2.556 seconds)


.. _sphx_glr_download_examples_parallel_plot_streaming_pipeline.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_streaming_pipeline.py <plot_streaming_pipeline.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_streaming_pipeline.ipynb <plot_streaming_pipeline.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
