{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nUsage of Checkpoints in Automatic Machine Learning (AutoML)\n=============================================================\n\nThis demonstrates how you can use checkpoints in a pipeline to save computing time when doing a hyperparameter search.\n\n..\n    Copyright 2019, Neuraxio Inc.\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n\n..\n    Thanks to Umaneo Technologies Inc. for their contributions to this Machine Learning\n    project, visit https://www.umaneo.com/ for more information on Umaneo Technologies Inc.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nfrom neuraxle.checkpoints import DefaultCheckpoint\nfrom neuraxle.hyperparams.distributions import RandInt\nfrom neuraxle.hyperparams.space import HyperparameterSpace\nfrom neuraxle.metaopt.random import RandomSearch\nfrom neuraxle.pipeline import ResumablePipeline, DEFAULT_CACHE_FOLDER, Pipeline\nfrom neuraxle.steps.loop import ForEachDataInput\nfrom neuraxle.steps.misc import Sleep\nfrom neuraxle.steps.numpy import MultiplyByN\n\n\ndef main(tmpdir, sleep_time: float = 0, n_iter: int = 10):\n    DATA_INPUTS = np.array(range(10))\n    EXPECTED_OUTPUTS = np.array(range(10, 20))\n\n    HYPERPARAMETER_SPACE = HyperparameterSpace({\n        'multiplication_1__multiply_by': RandInt(1, 2),\n        'multiplication_2__multiply_by': RandInt(1, 2),\n        'multiplication_3__multiply_by': RandInt(1, 2),\n    })\n\n    print('Classic Pipeline:')\n\n    pipeline = Pipeline([\n        ('multiplication_1', MultiplyByN()),\n        ('sleep_1', ForEachDataInput(Sleep(sleep_time))),\n        ('multiplication_2', MultiplyByN()),\n        ('sleep_2', ForEachDataInput(Sleep(sleep_time))),\n        ('multiplication_3', MultiplyByN()),\n    ]).set_hyperparams_space(HYPERPARAMETER_SPACE)\n\n    time_a = time.time()\n    best_model = RandomSearch(\n        pipeline,\n        n_iter=n_iter,\n        higher_score_is_better=True\n    ).fit(DATA_INPUTS, EXPECTED_OUTPUTS)\n    outputs = best_model.transform(DATA_INPUTS)\n    time_b = time.time()\n\n    actual_score = mean_squared_error(EXPECTED_OUTPUTS, outputs)\n    print('{0} seconds'.format(time_b - time_a))\n    print('output: {0}'.format(outputs))\n    print('smallest mse: {0}'.format(actual_score))\n    print('best hyperparams: {0}'.format(pipeline.get_hyperparams()))\n\n    assert isinstance(actual_score, float)\n    assert isinstance(outputs, np.ndarray)\n\n    print('Resumable Pipeline:')\n\n    pipeline = ResumablePipeline([\n        ('multiplication_1', MultiplyByN()),\n        ('sleep_1', ForEachDataInput(Sleep(sleep_time))),\n        DefaultCheckpoint(),\n        ('multiplication_2', MultiplyByN()),\n        ('sleep_2', ForEachDataInput(Sleep(sleep_time))),\n        DefaultCheckpoint(),\n        ('multiplication_3', MultiplyByN())\n    ], cache_folder=tmpdir).set_hyperparams_space(HYPERPARAMETER_SPACE)\n\n    time_a = time.time()\n    best_model = RandomSearch(\n        pipeline,\n        n_iter=n_iter,\n        higher_score_is_better=True\n    ).fit(DATA_INPUTS, EXPECTED_OUTPUTS)\n    outputs = best_model.transform(DATA_INPUTS)\n    time_b = time.time()\n    pipeline.flush_all_cache()\n\n    actual_score = mean_squared_error(EXPECTED_OUTPUTS, outputs)\n    print('{0} seconds'.format(time_b - time_a))\n    print('output: {0}'.format(outputs))\n    print('smallest mse: {0}'.format(actual_score))\n    print('best hyperparams: {0}'.format(pipeline.get_hyperparams()))\n\n    assert isinstance(actual_score, float)\n    assert isinstance(outputs, np.ndarray)\n\n\nif __name__ == \"__main__\":\n    main(DEFAULT_CACHE_FOLDER, sleep_time=0.01, n_iter=30)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}