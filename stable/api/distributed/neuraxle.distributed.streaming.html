

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

<meta property="og:title" content="neuraxle.distributed.streaming" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://www.neuraxle.org/stable/api/distributed/neuraxle.distributed.streaming.html" />
  
<meta property="og:site_name" content="Neuraxle" />
  
<meta property="og:description" content="Module-level documentation for neuraxle.distributed.streaming. Here is an inheritance diagram, including dependencies to other base modules of Neuraxle:, Streaming Pipelines for Parallel and Queued..." />
  
<meta property="og:image" content="https://www.neuraxle.org/stable/_images/sphx_glr_plot_streaming_pipeline_thumb.png" />
  
<meta property="og:image:alt" content="Parallel processing in Neuraxle" />
  
<meta property="og:locale" content="en_US" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>neuraxle.distributed.streaming &mdash; Neuraxle 0.8.0 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://www.neuraxle.org/api/distributed/neuraxle.distributed.streaming.html"/>
  

  
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-PWQLPZ3');</script>
  <!-- End Google Tag Manager -->

  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="neuraxle.logging.logging" href="../logging/neuraxle.logging.logging.html" />
    <link rel="prev" title="neuraxle.metaopt.hyperopt.tpe" href="../metaopt/hyperopt/neuraxle.metaopt.hyperopt.tpe.html" /> 

  <link href="https://fonts.googleapis.com/css?family=Share|Share+Tech+Mono" rel="stylesheet">
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search > a {
      color: #ff6201;
    }
    .wy-side-nav-search > div.version {
      color: #ff6201;
    }
    .wy-side-nav-search, .wy-nav-top {
      color: #ff6201;
    }
    /* Sidebar */
    .wy-nav-side {
    }
  </style>
</head>

<body class="wy-body-for-nav">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PWQLPZ3"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #FCFCFC" >
          

          
            
              <a href="https://www.neuraxle.org/" class="icon">
                <img src="../../_static/neuraxle_logo.png" class="logo" alt="Logo"/>
              </a>
          

          
            <a href="https://www.neuraxio.com/" class="icon icon-home"> Neuraxio</a>/<a href="../../index.html" > Neuraxle
          
          </a>

          
            
            
              <div class="version">
                0.8.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About Neuraxle</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Neuraxle/README.html">Neuraxle Pipelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/README.html#documentation">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/README.html#installation">Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Neuraxle/README.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Neuraxle/README.html#license">License</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Neuraxle/README.html#citation">Citation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Neuraxle/README.html#contributors">Contributors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Neuraxle/README.html#supported-by">Supported By</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../comparison_to_other_frameworks.html">Comparison to Other Machine Learning Pipeline Frameworks, and Compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#scikit-learn">scikit-learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#apache-beam">Apache Beam</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#spacy">spaCy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#kubeflow">Kubeflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#tensorflow">TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../comparison_to_other_frameworks.html#hyperopt">Hyperopt</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../scikit-learn_problems_solutions.html">Solutions to Scikit-Learn’s Biggest Problems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#definitions">Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#inability-to-reasonably-do-automatic-machine-learning-automl">Inability to Reasonably do Automatic Machine Learning (AutoML)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-defining-the-search-space-hyperparameter-distributions">Problem: Defining the Search Space (Hyperparameter Distributions)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-defining-hyperparameters-in-the-constructor-is-limiting">Problem: Defining Hyperparameters in the Constructor is Limiting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-different-train-and-test-behavior">Problem: Different Train and Test Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-you-trained-a-pipeline-and-you-want-feedback-statistics-on-its-learning">Problem: You trained a Pipeline and You Want Feedback Statistics on its Learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#inability-to-reasonably-do-deep-learning-pipelines">Inability to Reasonably do Deep Learning Pipelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-scikit-learn-hardly-allows-for-mini-batch-gradient-descent-incremental-fit">Problem: Scikit-Learn Hardly Allows for Mini-Batch Gradient Descent (Incremental Fit)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-initializing-the-pipeline-and-deallocating-resources">Problem: Initializing the Pipeline and Deallocating Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-it-is-difficult-to-use-other-deep-learning-dl-libraries-in-scikit-learn">Problem: It is Difficult to Use Other Deep Learning (DL) Libraries in Scikit-Learn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-the-ability-to-transform-output-labels">Problem: The Ability to Transform Output Labels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#not-ready-for-production-nor-for-complex-pipelines">Not ready for Production nor for Complex Pipelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-processing-3d-4d-or-nd-data-in-your-pipeline-with-steps-made-for-lower-dimensionnal-data">Problem: Processing 3D, 4D, or ND Data in your Pipeline with Steps Made for Lower-Dimensionnal Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-modify-a-pipeline-along-the-way-such-as-for-pre-training-or-fine-tuning">Problem: Modify a Pipeline Along the Way, such as for Pre-Training or Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-getting-model-attributes-from-scikit-learn-pipeline">Problem: Getting Model Attributes from Scikit-Learn Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../scikit-learn_problems_solutions.html#problem-you-can-t-parallelize-nor-save-pipelines-using-steps-that-can-t-be-serialized-as-is-by-joblib">Problem: You can’t Parallelize nor Save Pipelines Using Steps that Can’t be Serialized “as-is” by Joblib</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../awesome_neuraxle.html">Awesome Neuraxle </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#contents">Contents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#examples-articles">Examples &amp; Articles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#courses-training">Courses &amp; Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#videos">Videos</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#projects">Projects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#community">Community</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../awesome_neuraxle.html#license">License</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html">Contributing to Neuraxle</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#first-steps">First steps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#before-coding">Before coding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#pull-requests">Pull Requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#code-reviews">Code Reviews</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#reviewing-other-s-code">Reviewing other’s code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/CONTRIBUTING.html#publishing-project-to-pypi">Publishing project to PyPI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Neuraxle/.github/CODE_OF_CONDUCT.html">Code of conduct</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/.github/CODE_OF_CONDUCT.html#respect">Respect</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/.github/CODE_OF_CONDUCT.html#politeness">Politeness</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Neuraxle/.github/CODE_OF_CONDUCT.html#code-reviews">Code reviews</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../license.html">License</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../license.html#summary-of-the-license">Summary of the License</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../walkthroughs.html">&gt;&gt;&gt; Hands-On Walkthroughs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../intro.html">Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#encapsulate-models-and-data-transformers">Encapsulate Models and Data Transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#pipe-and-filter">Pipe and Filter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#features">Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#wrapper-a-k-a-decorator-classes">Wrapper (a.k.a. Decorator) classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#pipelines-for-minibatching-and-parallel-processing">Pipelines for Minibatching and Parallel Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#repository-for-lazy-data-loading">Repository for lazy data loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#training-your-pipeline">Training your pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#serializing-your-pipeline">Serializing your pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../intro.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../classes_and_modules_overview.html">Class diagrams and inheritance charts of Neuraxle objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#the-mixin-design-pattern-in-machine-learning">The Mixin design pattern in machine learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#steps-containing-other-steps-as-the-composite-design-pattern-in-machine-learning">Steps containing other steps as the composite design pattern in machine learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#scikit-learn-s-pipeline-pipeline-class-and-how-to-shift-to-parallel-deep-learning">Scikit-learn’s pipeline.Pipeline class and how to shift to parallel deep learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../classes_and_modules_overview.html#examples-using-neuraxle-pipeline-pipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.pipeline.Pipeline</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../classes_and_modules_overview.html#examples-using-neuraxle-distributed-streaming-sequentialqueuedpipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.SequentialQueuedPipeline</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#featureunion-to-compute-steps-in-parallel-and-join-their-results">FeatureUnion to compute steps in parallel and join their results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../classes_and_modules_overview.html#examples-using-neuraxle-union-featureunion">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.union.FeatureUnion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#automl-module-to-automatically-tune-hyperparameters-of-your-pipelines">AutoML module to automatically tune hyperparameters of your pipelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../classes_and_modules_overview.html#examples-using-neuraxle-metaopt-auto-ml-automl">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.metaopt.auto_ml.AutoML</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../classes_and_modules_overview.html#all-the-base-classes-of-neuraxle-together">All the base classes of Neuraxle together</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../hyperparameter_tuning.html">Automatic Hyperparameter Tuning / AutoML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../hyperparameter_tuning.html#AutoML-loop">AutoML loop</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Define-your-problem">Define your problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Define-your-pipeline">Define your pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Choose-a-validation-splitter">Choose a validation splitter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Define-a-the-main-scoring-metric-with-a-first-MetricsCallback">Define a the main scoring metric with a first MetricsCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Add-other-metric-callbacks-with-MetricCallback-(optional)">Add other metric callbacks with MetricCallback (optional)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Select-an-hyperparams-repository">Select an hyperparams repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Select-an-hyperparams-optimizer">Select an hyperparams optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Create,-and-launch-AutoML-loop">Create, and launch AutoML loop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Get-best-model-and-measure-test-accuracy">Get best model and measure test accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hyperparameter_tuning.html#Additional-note-:-model-selection-as-an-hyperparameter">Additional note : model selection as an hyperparameter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../handler_methods.html">Handler Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#handle_fit_transform">handle_fit_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#handle_fit">handle_fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#handle_transform">handle_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#When-to-use-handler-methods-?">When to use handler methods ?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#HandleOnlyMixin">HandleOnlyMixin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#ForceHandleMixin">ForceHandleMixin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#ForceHandleOnlyMixin">ForceHandleOnlyMixin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../handler_methods.html#Examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#ForEach">ForEach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#ToNumpy">ToNumpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#Transform-Expected-Outputs">Transform Expected Outputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#Expand-The-DataContainer">Expand The DataContainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../handler_methods.html#Reversible-Pipeline">Reversible Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../step_saving_and_lifecycle.html">Step Saving &amp; Lifecycle</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Lifecycle">Lifecycle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Step-Saving">Step Saving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Saver">Saver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Custom-Saver-Example">Custom Saver Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Saving-Example">Saving Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Pipeline">Pipeline</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Full-Dump-Saving">Full Dump Saving</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../step_saving_and_lifecycle.html#Full-Dump-Loading">Full Dump Loading</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../time_series_processing.html">Time Series Processing Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#The-Dataset">The Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#The-task">The task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#Video-dataset-overview">Video dataset overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#Details-about-the-input-data">Details about the input data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#Loading-the-Dataset">Loading the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#Part-1---How-would-you-code-this-in-a-typical-ML-project-using-Scikit-learn">Part 1 - How would you code this in a typical ML project using Scikit-learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../time_series_processing.html#Part-2---How-to-code-a-similar-pipeline---but-cleaner---using-Neuraxle">Part 2 - How to code a similar pipeline - but cleaner - using Neuraxle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../random_distributions.html">Random Distributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Plotting-Each-Hyperparameter-Distribution">Plotting Each Hyperparameter Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Discrete-Distributions">Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#RandInt">RandInt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Boolean">Boolean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Choice">Choice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Priority-Choice">Priority Choice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Continuous-Distributions">Continuous Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Uniform">Continuous Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Loguniform">Continuous Loguniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Normal">Continuous Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Lognormal">Continuous Lognormal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Normal-Clipped">Continuous Normal Clipped</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Continuous-Lognormal-Clipped">Continuous Lognormal Clipped</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Quantized-Hyperparameter-Distributions">Quantized Hyperparameter Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Quantized-Uniform">Quantized Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Repaired-Quantized-Uniform">Repaired Quantized Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Quantized-Log-Uniform">Quantized Log Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Quantized-Normal">Quantized Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#Quantized-Lognormal">Quantized Lognormal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Creating-your-own-distributions">Creating your own distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Using-Scipy-Distributions">Using Scipy Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../random_distributions.html#Creating-your-own-distributions-using-scipy">Creating your own distributions using scipy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#BaseCustomContinuousScipyDistribution">BaseCustomContinuousScipyDistribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../random_distributions.html#BaseCustomDiscreteScipyDistribution">BaseCustomDiscreteScipyDistribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rest_api_serving.html">REST API Serving</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Import-Packages">Import Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Load-your-Dataset">Load your Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Create-your-Pipeline">Create your Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Let’s-Train-and-Test">Let’s Train and Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Deploy-the-Pipeline">Deploy the Pipeline</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Write-a-step-to-decode-the-accepted-JSON-as-data-inputs">Write a step to decode the accepted JSON as data inputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Write-a-step-to-encode-the-returned-JSON-response">Write a step to encode the returned JSON response</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Finally-Serve-Predictions">Finally Serve Predictions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#API-Call-Example">API Call Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rest_api_serving.html#Next-Steps">Next Steps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Pipeline-Serialization">Pipeline Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Data-Transformation-Caching">Data Transformation Caching</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rest_api_serving.html#Checkpoints">Checkpoints</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">&gt;&gt;&gt; Practical Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#automl">AutoML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/auto_ml/plot_automl_loop_clean_kata.html">Usage of AutoML loop, and hyperparams with sklearn models.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#caching">Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#rest-api-model-serving">REST API Model Serving</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/deployment/plot_easy_rest_api_serving.html">Easy REST API Model Serving with Neuraxle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#getting-started">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/getting_started/plot_inverse_transform.html">Inverse Transforms in Neuraxle: How to Reverse a Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/getting_started/plot_nested_pipelines.html">Create Nested Pipelines in Neuraxle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/getting_started/plot_label_encoder_across_multiple_columns.html">Create label encoder across multiple columns</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/getting_started/plot_non_fittable_mixin.html">Create Pipeline Steps in Neuraxle that doesn’t fit or transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/getting_started/plot_force_handle_mixin.html">Create Pipeline Steps that require implementing only handler methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#hyperparameters">Hyperparameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/hyperparams/plot_hyperparams.html">Manipulate Hyperparameter Spaces for Hyperparameter Tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#parallel">Parallel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/parallel/plot_streaming_pipeline.html">Parallel processing in Neuraxle</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#neuraxle-hyperparameter-examples">Neuraxle hyperparameter examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/sklearn/plot_boston_housing_regression_with_model_stacking.html">Boston Housing Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/sklearn/plot_boston_housing_meta_optimization.html">Boston Housing Regression with Meta Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html">Time-related feature engineering with scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#data-exploration-on-the-bike-sharing-demand-dataset">Data exploration on the Bike Sharing Demand dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#time-based-cross-validation">Time-based cross-validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#gradient-boosting">Gradient Boosting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#naive-linear-regression">Naive linear regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#time-steps-as-categories">Time-steps as categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#trigonometric-features">Trigonometric features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#periodic-spline-features">Periodic spline features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#qualitative-analysis-of-the-impact-of-features-on-linear-model-predictions">Qualitative analysis of the impact of features on linear model predictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#modeling-pairwise-interactions-with-splines-and-polynomial-features">Modeling pairwise interactions with splines and polynomial features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#modeling-non-linear-feature-interactions-with-kernels">Modeling non-linear feature interactions with kernels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#concluding-remarks">Concluding remarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/sklearn/plot_cyclical_feature_engineering.html#source">Source</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../api.html">&gt;&gt;&gt; Complete API Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../neuraxle.base.html">neuraxle.base</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../neuraxle.base.html#neuraxle-s-base-classes">Neuraxle’s Base Classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-basestep">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.BaseStep</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-executioncontext">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.ExecutionContext</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-forcehandlemixin">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.ForceHandleMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-identity">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.Identity</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-metastep">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.MetaStep</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-nonfittablemixin">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.NonFittableMixin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.base.html#examples-using-neuraxle-base-nontransformablemixin">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.base.NonTransformableMixin</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../neuraxle.pipeline.html">neuraxle.pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../neuraxle.pipeline.html#neuraxle-s-pipeline-classes">Neuraxle’s Pipeline Classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.pipeline.html#examples-using-neuraxle-pipeline-basepipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.pipeline.BasePipeline</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.pipeline.html#examples-using-neuraxle-pipeline-minibatchsequentialpipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.pipeline.MiniBatchSequentialPipeline</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.pipeline.html#examples-using-neuraxle-pipeline-pipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.pipeline.Pipeline</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../neuraxle.data_container.html">neuraxle.data_container</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../neuraxle.data_container.html#neuraxle-s-datacontainer-classes">Neuraxle’s DataContainer classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../neuraxle.union.html">neuraxle.union</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../neuraxle.union.html#union-of-features">Union of Features</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.union.html#examples-using-neuraxle-union-addfeatures">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.union.AddFeatures</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.union.html#examples-using-neuraxle-union-featureunion">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.union.FeatureUnion</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../neuraxle.union.html#examples-using-neuraxle-union-modelstacking">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.union.ModelStacking</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html">neuraxle.steps.numpy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html#pipeline-steps-based-on-numpy">Pipeline Steps Based on NumPy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html#examples-using-neuraxle-steps-numpy-multiplybyn">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.numpy.MultiplyByN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html#examples-using-neuraxle-steps-numpy-numpyravel">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.numpy.NumpyRavel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html#examples-using-neuraxle-steps-numpy-numpyshapeprinter">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.numpy.NumpyShapePrinter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.numpy.html#examples-using-neuraxle-steps-numpy-numpytranspose">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.numpy.NumpyTranspose</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.flow.html">neuraxle.steps.flow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.flow.html#neuraxle-s-flow-steps">Neuraxle’s Flow Steps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.flow.html#examples-using-neuraxle-steps-flow-chooseonestepof">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.flow.ChooseOneStepOf</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.data.html">neuraxle.steps.data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.data.html#data-steps">Data Steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.column_transformer.html">neuraxle.steps.column_transformer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.column_transformer.html#neuraxle-s-column-transformer-steps">Neuraxle’s Column Transformer Steps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.column_transformer.html#examples-using-neuraxle-steps-column-transformer-columntransformer">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.column_transformer.ColumnTransformer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.features.html">neuraxle.steps.features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.features.html#featurization-steps">Featurization Steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.sklearn.html">neuraxle.steps.sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.sklearn.html#pipeline-steps-based-on-scikit-learn">Pipeline Steps Based on Scikit-Learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.sklearn.html#examples-using-neuraxle-steps-sklearn-ridgemodelstacking">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.sklearn.RidgeModelStacking</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.sklearn.html#examples-using-neuraxle-steps-sklearn-sklearnwrapper">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.sklearn.SKLearnWrapper</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.loop.html">neuraxle.steps.loop</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.loop.html#pipeline-steps-for-looping">Pipeline Steps For Looping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.loop.html#examples-using-neuraxle-steps-loop-flattenforeach">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.loop.FlattenForEach</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.loop.html#examples-using-neuraxle-steps-loop-foreach">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.loop.ForEach</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.output_handlers.html">neuraxle.steps.output_handlers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.output_handlers.html#output-handlers-steps">Output Handlers Steps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.output_handlers.html#examples-using-neuraxle-steps-output-handlers-outputtransformerwrapper">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.output_handlers.OutputTransformerWrapper</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../steps/neuraxle.steps.misc.html">neuraxle.steps.misc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../steps/neuraxle.steps.misc.html#miscelaneous-pipeline-steps">Miscelaneous Pipeline Steps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../steps/neuraxle.steps.misc.html#examples-using-neuraxle-steps-misc-sleep">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.steps.misc.Sleep</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html">neuraxle.hyperparams.distributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html#hyperparameter-distributions">Hyperparameter Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html#examples-using-neuraxle-hyperparams-distributions-boolean">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.hyperparams.distributions.Boolean</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html#examples-using-neuraxle-hyperparams-distributions-choice">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.hyperparams.distributions.Choice</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html#examples-using-neuraxle-hyperparams-distributions-loguniform">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.hyperparams.distributions.LogUniform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.distributions.html#examples-using-neuraxle-hyperparams-distributions-randint">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.hyperparams.distributions.RandInt</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.scipy_distributions.html">neuraxle.hyperparams.scipy_distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.space.html">neuraxle.hyperparams.space</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.space.html#hyperparameter-dictionary-conversions">Hyperparameter Dictionary Conversions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../hyperparams/neuraxle.hyperparams.space.html#examples-using-neuraxle-hyperparams-space-hyperparameterspace">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.hyperparams.space.HyperparameterSpace</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/neuraxle.metaopt.auto_ml.html">neuraxle.metaopt.auto_ml</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/neuraxle.metaopt.auto_ml.html#neuraxle-s-automl-classes">Neuraxle’s AutoML Classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../metaopt/neuraxle.metaopt.auto_ml.html#examples-using-neuraxle-metaopt-auto-ml-automl">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.metaopt.auto_ml.AutoML</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/neuraxle.metaopt.callbacks.html">neuraxle.metaopt.callbacks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/neuraxle.metaopt.callbacks.html#neuraxle-s-training-callbacks-classes">Neuraxle’s training callbacks classes.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../metaopt/neuraxle.metaopt.callbacks.html#examples-using-neuraxle-metaopt-callbacks-metriccallback">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.metaopt.callbacks.MetricCallback</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../metaopt/neuraxle.metaopt.callbacks.html#examples-using-neuraxle-metaopt-callbacks-scoringcallback">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.metaopt.callbacks.ScoringCallback</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/neuraxle.metaopt.context.html">neuraxle.metaopt.context</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/neuraxle.metaopt.context.html#neuraxle-s-automl-context-management">Neuraxle’s AutoML Context Management</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/neuraxle.metaopt.optimizer.html">neuraxle.metaopt.optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/neuraxle.metaopt.optimizer.html#neuraxle-s-hyperparameter-optimizer-base-classes">Neuraxle’s Hyperparameter Optimizer Base Classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/neuraxle.metaopt.validation.html">neuraxle.metaopt.validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/neuraxle.metaopt.validation.html#validation">Validation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.vanilla.html">neuraxle.metaopt.data.vanilla</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.vanilla.html#neuraxle-s-base-hyperparameter-repository-classes">Neuraxle’s Base Hyperparameter Repository Classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.reporting.html">neuraxle.metaopt.data.reporting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.reporting.html#neuraxle-s-automl-metric-reporting-classes">Neuraxle’s AutoML Metric Reporting classes.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.aggregates.html">neuraxle.metaopt.data.aggregates</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/data/neuraxle.metaopt.data.aggregates.html#neuraxle-s-automl-scope-manager-classes">Neuraxle’s AutoML Scope Manager Classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.repo.html">neuraxle.metaopt.repositories.repo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.repo.html#neuraxle-s-hyperparameter-repository-base-classes">Neuraxle’s Hyperparameter Repository Base Classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.json.html">neuraxle.metaopt.repositories.json</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.json.html#neuraxle-s-json-hyperparameter-repository-classes">Neuraxle’s JSON Hyperparameter Repository Classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.json.html#examples-using-neuraxle-metaopt-repositories-json-hyperparamsondiskrepository">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.metaopt.repositories.json.HyperparamsOnDiskRepository</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.db.html">neuraxle.metaopt.repositories.db</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/repositories/neuraxle.metaopt.repositories.db.html#neuraxle-s-sqlalchemy-hyperparameter-repository-classes">Neuraxle’s SQLAlchemy Hyperparameter Repository Classes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../metaopt/hyperopt/neuraxle.metaopt.hyperopt.tpe.html">neuraxle.metaopt.hyperopt.tpe</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../metaopt/hyperopt/neuraxle.metaopt.hyperopt.tpe.html#tree-parzen-estimator">Tree parzen estimator</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">neuraxle.distributed.streaming</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#streaming-pipelines-for-parallel-and-queued-data-processing">Streaming Pipelines for Parallel and Queued Data Processing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#examples-using-neuraxle-distributed-streaming-sequentialqueuedpipeline">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.SequentialQueuedPipeline</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../logging/neuraxle.logging.logging.html">neuraxle.logging.logging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../logging/neuraxle.logging.logging.html#neuraxle-s-logging-module">Neuraxle’s Logging module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../logging/neuraxle.logging.warnings.html">neuraxle.logging.warnings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../logging/neuraxle.logging.warnings.html#neuraxle-s-deprecation-warnings">Neuraxle’s Deprecation Warnings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../rest/neuraxle.rest.flask.html">neuraxle.rest.flask</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../rest/neuraxle.rest.flask.html#neuraxle-s-flask-wrapper-classes">Neuraxle’s Flask Wrapper classes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../rest/neuraxle.rest.flask.html#examples-using-neuraxle-rest-flask-flaskrestapiwrapper">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.rest.flask.FlaskRestApiWrapper</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../rest/neuraxle.rest.flask.html#examples-using-neuraxle-rest-flask-jsondatabodydecoder">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.rest.flask.JSONDataBodyDecoder</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../rest/neuraxle.rest.flask.html#examples-using-neuraxle-rest-flask-jsondataresponseencoder">Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.rest.flask.JSONDataResponseEncoder</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          <li class="toctree-l1">
            <a class="reference internal" href="https://www.neuraxio.com/blogs/news"
                                    style="background:#ff6201; color:#fff; text-decoration-line: underline;" target="_blank">
            Neuraxio Blog Articles [↗️]</a>
            <a class="reference internal" href="https://www.neuraxio.com/blogs/news/our-top-learning-resources-for-ai-programmers?utm_source=neuraxle_doc"
                                    style="background:#ffaf00; color:#fff; text-decoration-line: underline;" target="_blank">
            Learn AI Programming [↗️]</a>
            <a class="reference internal" href="https://www.jobs.neuraxio.com/"
                                    style="background:#111; color:#fff; text-decoration-line: underline;" target="_blank">
            Jobs [↗️]</a>
          </li>

          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="https://www.neuraxio.com/"> Neuraxio</a>/<a href="../../index.html">Neuraxle</a>
        
      </nav>


      <div class="wy-nav-content">
        <a href="https://github.com/Neuraxio/Neuraxle"><img style="position: absolute; border: 0; top: 0; right: 0;" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../api.html">&gt;&gt;&gt; Complete API Documentation</a> &raquo;</li>
        
      <li>neuraxle.distributed.streaming</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <!-- <a href="../../_sources/api/distributed/neuraxle.distributed.streaming.rst.txt" rel="nofollow"> View page source</a> -->
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="neuraxle-distributed-streaming">
<h1>neuraxle.distributed.streaming<a class="headerlink" href="#neuraxle-distributed-streaming" title="Permalink to this headline">¶</a></h1>
<p>Module-level documentation for neuraxle.distributed.streaming. Here is an inheritance diagram,
including dependencies to other base modules of Neuraxle:</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<span class="target" id="module-neuraxle.distributed.streaming"></span><section id="streaming-pipelines-for-parallel-and-queued-data-processing">
<h2>Streaming Pipelines for Parallel and Queued Data Processing<a class="headerlink" href="#streaming-pipelines-for-parallel-and-queued-data-processing" title="Permalink to this headline">¶</a></h2>
<p>Neuraxle steps for streaming data in parallel in the pipeline.</p>
<p>Pipelines can stream data in queues with workers for each steps.
Max queue sizes can be set, as well as number of clones per steps
for the transformers.</p>
<p class="rubric">Functions</p>
<table class="longtable docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.pickle_exception_into_task" title="neuraxle.distributed.streaming.pickle_exception_into_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pickle_exception_into_task</span></code></a>(task, err)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.worker_function" title="neuraxle.distributed.streaming.worker_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">worker_function</span></code></a>(worker, context, use_savers, …)</p></td>
<td><p>Worker function that transforms the items inside the queue of items to process.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Classes</p>
<table class="longtable docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="neuraxle.distributed.streaming.BaseQueuedPipeline"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseQueuedPipeline</span></code></a>(steps, Tuple[int, …)</p></td>
<td><p>Sub class of <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.MinibatchError" title="neuraxle.distributed.streaming.MinibatchError"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchError</span></code></a>(minibatch_dact, step_name, err)</p></td>
<td><p>Data object to represent an error in a minibatch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion" title="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParallelQueuedFeatureUnion</span></code></a>(steps, Tuple[int, …)</p></td>
<td><p>Using <code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>, run all steps in parallel using QueueWorkers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper" title="neuraxle.distributed.streaming.ParallelWorkersWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParallelWorkersWrapper</span></code></a>(wrapped, …)</p></td>
<td><p>Start multiple Process or Thread that consumes items from the minibatch DACT Queue, and produces them on the next registered consumers’ queue.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.QueuedMinibatchTask" title="neuraxle.distributed.streaming.QueuedMinibatchTask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QueuedMinibatchTask</span></code></a>(minibatch_dact, step_name)</p></td>
<td><p>Data object to contain the minibatch processed by producers and consumers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline" title="neuraxle.distributed.streaming.SequentialQueuedPipeline"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SequentialQueuedPipeline</span></code></a>(steps, Tuple[int, …)</p></td>
<td><p>Using <code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>, run all steps sequentially even if they are in separate processes or threads.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuraxle.distributed.streaming.WorkersJoiner" title="neuraxle.distributed.streaming.WorkersJoiner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">WorkersJoiner</span></code></a>(batch_size, …)</p></td>
<td><p>Consume the results of the other <a class="reference internal" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="neuraxle.distributed.streaming._ProducerConsumerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">_ProducerConsumerMixin</span></code></a> workers to join their data.</p></td>
</tr>
</tbody>
</table>
<section id="examples-using-neuraxle-distributed-streaming-sequentialqueuedpipeline">
<span id="sphx-glr-backref-neuraxle-distributed-streaming-sequentialqueuedpipeline"></span><span id="sphx-glr-backref-neuraxle-distributed-streaming-queuedminibatchtask"></span><span id="sphx-glr-backref-neuraxle-distributed-streaming-parallelworkerswrapper"></span><span id="sphx-glr-backref-neuraxle-distributed-streaming-parallelqueuedfeatureunion"></span><span id="sphx-glr-backref-neuraxle-distributed-streaming-minibatcherror"></span><span id="sphx-glr-backref-neuraxle-distributed-streaming-basequeuedpipeline"></span><h3>Examples using <code class="docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.SequentialQueuedPipeline</span></code><a class="headerlink" href="#examples-using-neuraxle-distributed-streaming-sequentialqueuedpipeline" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This demonstrates how to stream data in parallel in a Neuraxle pipeline. The pipeline steps&#x27; pa..."><figure class="align-center" id="id1">
<img alt="Parallel processing in Neuraxle" src="../../_images/sphx_glr_plot_streaming_pipeline_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../examples/parallel/plot_streaming_pipeline.html#sphx-glr-examples-parallel-plot-streaming-pipeline-py"><span class="std std-ref">Parallel processing in Neuraxle</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-clear"></div><div class="line-block">
<div class="line"><br /></div>
</div>
<dl class="class">
<dt id="neuraxle.distributed.streaming._ProducerConsumerStepSaver">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">_ProducerConsumerStepSaver</code><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L52"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerStepSaver" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseSaver" title="neuraxle.base.BaseSaver"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.base.BaseSaver</span></code></a></p>
<p>Saver for <a class="reference internal" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="neuraxle.distributed.streaming._ProducerConsumerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">_ProducerConsumerMixin</span></code></a>.
This saver class makes sure that the non-picklable queue
is deleted upon saving for multiprocessing steps.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerStepSaver.save_step">
<code class="descname">save_step</code><span class="sig-paren">(</span><em>step: neuraxle.base.BaseTransformer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.base.BaseTransformer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerStepSaver.save_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a step or a step’s parts using the execution context.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseTransformer" title="neuraxle.base.BaseTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformer</span></code></a></p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>step</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseTransformer" title="neuraxle.base.BaseTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformer</span></code></a>) – step to save</p></li>
<li><p><strong>context</strong> – execution context</p></li>
<li><p><strong>save_savers</strong> – </p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerStepSaver.can_load">
<code class="descname">can_load</code><span class="sig-paren">(</span><em>step: neuraxle.base.BaseTransformer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L66"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerStepSaver.can_load" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns true if we can load the given step with the given execution context.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>step</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseTransformer" title="neuraxle.base.BaseTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseTransformer</span></code></a>) – step to load</p></li>
<li><p><strong>context</strong> – execution context to load from</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerStepSaver.load_step">
<code class="descname">load_step</code><span class="sig-paren">(</span><em>step: neuraxle.base.BaseTransformer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.base.BaseTransformer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L69"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerStepSaver.load_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Load step with execution context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> – step to load</p></li>
<li><p><strong>context</strong> – execution context to load from</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loaded base step</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming._ProducerConsumerStepSaver._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerStepSaver._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="exception">
<dt id="neuraxle.distributed.streaming._QueueDestroyedError">
<em class="property">exception </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">_QueueDestroyedError</code><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L75"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._QueueDestroyedError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#EOFError" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">EOFError</span></code></a></p>
<p>Error raised when the queue is destroyed.</p>
</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">_ProducerConsumerMixin</code><span class="sig-paren">(</span><em>max_queued_minibatches: int = 0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L85"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../neuraxle.base.html#neuraxle.base.MixinForBaseTransformer" title="neuraxle.base.MixinForBaseTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.base.MixinForBaseTransformer</span></code></a></p>
<p>A class to represent a step that can receive minibatches from a producer in its queue to consume them.
Once minibatches are consumed by the present step, they are produced back to the next consumers in line.</p>
<p>The Queue in self is the one at the entry to be consumed by self. The output queue is external, in the registred consumers.</p>
<p>Therefore, in this sense, consumers and producers are both themselves instances of _HasQueueMixin and play the two roles unless they are the first an lasts of their multiprocessing pipelines.
They will thus be used to consume the produced tasks added to them in their other threads or processes.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>max_queued_minibatches: int = 0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._setup">
<code class="descname">_setup</code><span class="sig-paren">(</span><em>context: Optional[neuraxle.base.ExecutionContext] = None</em><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._setup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._init_queue">
<code class="descname">_init_queue</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L109"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._init_queue" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._teardown">
<code class="descname">_teardown</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L113"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._teardown" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin.register_consumer">
<code class="descname">register_consumer</code><span class="sig-paren">(</span><em>recepient: neuraxle.distributed.streaming._ProducerConsumerMixin</em><span class="sig-paren">)</span> &#x2192; neuraxle.distributed.streaming._ProducerConsumerMixin<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L118"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin.register_consumer" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a consumer to self.consumers so that when self produces a minibatch, it allows consumers to consume it.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin.put_minibatch_produced_to_next_consumers">
<code class="descname">put_minibatch_produced_to_next_consumers</code><span class="sig-paren">(</span><em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L127"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin.put_minibatch_produced_to_next_consumers" title="Permalink to this definition">¶</a></dt>
<dd><p>Push a minibatch to all subsequent consumers to allow them to consume it. If the task is terminal, close our own queue.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin.put_minibatch_produced">
<code class="descname">put_minibatch_produced</code><span class="sig-paren">(</span><em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L137"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin.put_minibatch_produced" title="Permalink to this definition">¶</a></dt>
<dd><p>Put a minibatch in queue.
The caller of this method is the producer of the minibatch and is external to self.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._ensure_task_picklable">
<code class="descname">_ensure_task_picklable</code><span class="sig-paren">(</span><em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L150"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._ensure_task_picklable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._get_minibatch_to_consume">
<code class="descname">_get_minibatch_to_consume</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; neuraxle.distributed.streaming.QueuedMinibatchTask<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L157"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._get_minibatch_to_consume" title="Permalink to this definition">¶</a></dt>
<dd><p>Get last minibatch in queue. The caller of this method is probably self,
that is why the method is private (starts with an underscore).
This method can raise an EOFError.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin.join">
<code class="descname">join</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L174"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin.join" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming._ProducerConsumerMixin._allow_exit_without_queue_flush">
<code class="descname">_allow_exit_without_queue_flush</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L181"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming._ProducerConsumerMixin._allow_exit_without_queue_flush" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.QueuedMinibatchTask">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">QueuedMinibatchTask</code><span class="sig-paren">(</span><em>minibatch_dact: neuraxle.data_container.DataContainer</em>, <em>step_name: str = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L186"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.QueuedMinibatchTask" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Data object to contain the minibatch processed by producers and consumers.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming.QueuedMinibatchTask.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>minibatch_dact: neuraxle.data_container.DataContainer</em>, <em>step_name: str = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L191"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.QueuedMinibatchTask.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.QueuedMinibatchTask.is_error">
<code class="descname">is_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L195"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.QueuedMinibatchTask.is_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.QueuedMinibatchTask.to_error">
<code class="descname">to_error</code><span class="sig-paren">(</span><em>error: Exception</em><span class="sig-paren">)</span> &#x2192; neuraxle.distributed.streaming.MinibatchError<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L198"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.QueuedMinibatchTask.to_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.MinibatchError">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">MinibatchError</code><span class="sig-paren">(</span><em>minibatch_dact: neuraxle.data_container.DataContainer</em>, <em>step_name: str</em>, <em>err: Exception</em>, <em>traceback_msg=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L211"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.MinibatchError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neuraxle.distributed.streaming.QueuedMinibatchTask" title="neuraxle.distributed.streaming.QueuedMinibatchTask"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.QueuedMinibatchTask</span></code></a></p>
<p>Data object to represent an error in a minibatch.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming.MinibatchError.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>minibatch_dact: neuraxle.data_container.DataContainer</em>, <em>step_name: str</em>, <em>err: Exception</em>, <em>traceback_msg=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L216"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.MinibatchError.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.MinibatchError.is_error">
<code class="descname">is_error</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L221"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.MinibatchError.is_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.MinibatchError.get_err">
<code class="descname">get_err</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Exception<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L224"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.MinibatchError.get_err" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="neuraxle.distributed.streaming.worker_function">
<code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">worker_function</code><span class="sig-paren">(</span><em>worker: neuraxle.distributed.streaming.ParallelWorkersWrapper, context: neuraxle.base.ExecutionContext, use_savers: bool, logging_queue: Optional[multiprocessing.context.BaseContext.Queue]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L230"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.worker_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Worker function that transforms the items inside the queue of items to process.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>queue_worker</strong> – step to transform</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExecutionContext</span></code></a>) – execution context</p></li>
<li><p><strong>use_savers</strong> (<code class="docutils literal notranslate"><span class="pre">bool</span></code>) – use savers</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="neuraxle.distributed.streaming.pickle_exception_into_task">
<code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">pickle_exception_into_task</code><span class="sig-paren">(</span><em>task</em>, <em>err</em><span class="sig-paren">)</span> &#x2192; neuraxle.distributed.streaming.MinibatchError<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L291"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.pickle_exception_into_task" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">ParallelWorkersWrapper</code><span class="sig-paren">(</span><em>wrapped: neuraxle.base.BaseTransformer</em>, <em>max_queued_minibatches: int = None</em>, <em>n_workers: int = 1</em>, <em>use_processes: bool = True</em>, <em>use_savers: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L297"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="neuraxle.distributed.streaming._ProducerConsumerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming._ProducerConsumerMixin</span></code></a>, <a class="reference internal" href="../neuraxle.base.html#neuraxle.base.MetaStep" title="neuraxle.base.MetaStep"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.base.MetaStep</span></code></a></p>
<p>Start multiple Process or Thread that consumes items from the minibatch DACT Queue, and produces them on the next registered consumers’ queue.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>wrapped: neuraxle.base.BaseTransformer</em>, <em>max_queued_minibatches: int = None</em>, <em>n_workers: int = 1</em>, <em>use_processes: bool = True</em>, <em>use_savers: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L302"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper._setup">
<code class="descname">_setup</code><span class="sig-paren">(</span><em>context: Optional[neuraxle.base.ExecutionContext] = None</em><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L320"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper._setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal method to setup the step. May be used by <a class="reference internal" href="../neuraxle.pipeline.html#neuraxle.pipeline.Pipeline" title="neuraxle.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>
to setup the pipeline progressively instead of all at once.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper.start">
<code class="descname">start</code><span class="sig-paren">(</span><em>context: neuraxle.base.ExecutionContext</em>, <em>logging_queue: Optional[multiprocessing.context.BaseContext.Queue] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L334"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper.start" title="Permalink to this definition">¶</a></dt>
<dd><p>Start multiple processes or threads with the worker function as a target.
These workers will consume minibatches from the queue and produce them on the next queue(s).
They are started as multiprocessing daemons, so that they will not block the main
process if there is an error requiring to exit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExecutionContext</span></code></a>) – An execution context that will be checked to be thread_safe.</p></li>
<li><p><strong>logging_queue</strong> – An optional logging_queue from the object <code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelLoggingConsumerThread</span></code> to pass and recover parallelized log records to. Not required for thread-only parallelism, only process-based parallelism.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper.reload_post_saving">
<code class="descname">reload_post_saving</code><span class="sig-paren">(</span><em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.distributed.streaming.ParallelWorkersWrapper<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L379"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper.reload_post_saving" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper.join">
<code class="descname">join</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L388"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper.join" title="Permalink to this definition">¶</a></dt>
<dd><p>Wait for workers to finish at least their capture of the logging calls.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper._teardown">
<code class="descname">_teardown</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L397"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper._teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Stop all processes on teardown.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper.stop">
<code class="descname">stop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L405"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper.stop" title="Permalink to this definition">¶</a></dt>
<dd><p>Stop all of the workers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming.ParallelWorkersWrapper._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelWorkersWrapper._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">BaseQueuedPipeline</code><span class="sig-paren">(</span><em>steps: List[Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]], batch_size: int, n_workers_per_step: int = None, max_queued_minibatches: int = None, data_joiner: neuraxle.base.BaseTransformer = None, use_processes: bool = False, use_savers: bool = False, keep_incomplete_batch: bool = True, default_value_data_inputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None, default_value_expected_outputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L429"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../neuraxle.pipeline.html#neuraxle.pipeline.MiniBatchSequentialPipeline" title="neuraxle.pipeline.MiniBatchSequentialPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.pipeline.MiniBatchSequentialPipeline</span></code></a></p>
<p>Sub class of <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>.
Transform data in many pipeline steps at once in parallel in the pipeline using multiprocessing Queues.</p>
<p>Example usage :</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Multiple ways of specifying the steps tuples exists to do various things:</span>
<span class="c1"># step name, step</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">SequentialQueuedPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;step_a&#39;</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;step_b&#39;</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
<span class="p">],</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_queued_minibatches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># step name, number of workers, step</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">SequentialQueuedPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;step_a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;step_b&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
<span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_queued_minibatches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># step name, number of workers, and max size</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">SequentialQueuedPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;step_a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;step_b&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">Identity</span><span class="p">()),</span>
<span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># step name, number of workers for each step, and additional argument for each worker</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">SequentialQueuedPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;step_a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;host&#39;</span><span class="p">,</span> <span class="s1">&#39;host1&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;host&#39;</span><span class="p">,</span> <span class="s1">&#39;host2&#39;</span><span class="p">)],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">Identity</span><span class="p">())</span>
<span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># step name, number of workers for each step, additional argument for each worker, and max size</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">SequentialQueuedPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;step_a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[(</span><span class="s1">&#39;host&#39;</span><span class="p">,</span> <span class="s1">&#39;host1&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;host&#39;</span><span class="p">,</span> <span class="s1">&#39;host2&#39;</span><span class="p">)],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">Identity</span><span class="p">())</span>
<span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># It&#39;s also possible to do parallel feature unions:</span>
<span class="n">n_workers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">worker_arguments</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;hyperparams&#39;</span><span class="p">,</span> <span class="n">HyperparameterSamples</span><span class="p">({</span><span class="s1">&#39;multiply_by&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_workers</span><span class="p">)]</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">ParallelQueuedFeatureUnion</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">,</span> <span class="n">worker_arguments</span><span class="p">,</span> <span class="n">MultiplyByN</span><span class="p">()),</span>
<span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_queued_minibatches</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>steps</strong> – pipeline steps.</p></li>
<li><p><strong>batch_size</strong> – number of elements to combine into a single batch.</p></li>
<li><p><strong>n_workers_per_step</strong> – number of workers to spawn per step.</p></li>
<li><p><strong>max_queued_minibatches</strong> – max number of batches inside the processing queue between the workers.</p></li>
<li><p><strong>data_joiner</strong> – transformer step to join streamed batches together at the end of the pipeline.</p></li>
<li><p><strong>use_processes</strong> – use processes instead of threads for parallel processing. multiprocessing.Process is used by default.</p></li>
<li><p><strong>use_savers</strong> – use savers to serialize steps for parallel processing. Recommended if using processes instead of threads.</p></li>
<li><p><strong>keep_incomplete_batch</strong> – (Optional.) A bool that indicates whether</p></li>
</ul>
</dd>
</dl>
<p>or not the last batch should be dropped in the case it has fewer than
<cite>batch_size</cite> elements; the default behavior is to keep the smaller batch.
:param default_value_data_inputs: expected_outputs default fill value
for padding and values outside iteration range, or <a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.StripAbsentValues" title="neuraxle.data_container.StripAbsentValues"><code class="xref py py-class docutils literal notranslate"><span class="pre">StripAbsentValues</span></code></a>
to trim absent values from the batch
:param default_value_expected_outputs: expected_outputs default fill value
for padding and values outside iteration range, or <a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.StripAbsentValues" title="neuraxle.data_container.StripAbsentValues"><code class="xref py py-class docutils literal notranslate"><span class="pre">StripAbsentValues</span></code></a>
to trim absent values from the batch</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>steps: List[Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]], batch_size: int, n_workers_per_step: int = None, max_queued_minibatches: int = None, data_joiner: neuraxle.base.BaseTransformer = None, use_processes: bool = False, use_savers: bool = False, keep_incomplete_batch: bool = True, default_value_data_inputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None, default_value_expected_outputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L493"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._parallel_wrap_all_steps_tuples">
<code class="descname">_parallel_wrap_all_steps_tuples</code><span class="sig-paren">(</span><em>all_step_tuples: List[Union[Tuple[str, BaseTransformerT], BaseTransformerT]]</em><span class="sig-paren">)</span> &#x2192; List[Union[Tuple[str, BaseTransformerT], BaseTransformerT]]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L534"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._parallel_wrap_all_steps_tuples" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap each step by a <code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code> to  allow data to flow in many pipeline steps at once in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>steps</strong> (<em>NameNWorkerStepTupleList</em>) – (name, n_workers, step)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>steps as tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._parallel_wrap_step_tuple">
<code class="descname">_parallel_wrap_step_tuple</code><span class="sig-paren">(</span><em>step_tuple: Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L550"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._parallel_wrap_step_tuple" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._parse_step_tuple">
<code class="descname">_parse_step_tuple</code><span class="sig-paren">(</span><em>step_tuple: Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]</em><span class="sig-paren">)</span> &#x2192; Tuple[str, int, int, List[Tuple], neuraxle.base.BaseTransformer]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L562"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._parse_step_tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all params necessary to create the QueuedPipeline for the given step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>step_tuple</strong> – the un-parsed tuple of steps</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tuple of (name, n_workers, max_queued_minibatches, actual_step)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">int</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.10)">int</a>, <a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseStep" title="neuraxle.base.BaseStep">BaseStep</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._will_process">
<code class="descname">_will_process</code><span class="sig-paren">(</span><em>data_container: neuraxle.data_container.DataContainer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; Tuple[neuraxle.data_container.DataContainer, neuraxle.base.ExecutionContext]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L595"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._will_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Setup streaming pipeline before any handler methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_container</strong> (<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataContainer</span></code></a>) – data container</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExecutionContext</span></code></a>) – execution context</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._setup">
<code class="descname">_setup</code><span class="sig-paren">(</span><em>context: neuraxle.base.ExecutionContext = None</em><span class="sig-paren">)</span> &#x2192; neuraxle.base.BaseTransformer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L609"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Connect the queued workers together so that the data can correctly flow through the pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExecutionContext</span></code></a>) – execution context</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>step</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../neuraxle.base.html#neuraxle.base.BaseStep" title="neuraxle.base.BaseStep">BaseStep</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline.fit_transform_data_container">
<code class="descname">fit_transform_data_container</code><span class="sig-paren">(</span><em>data_container: neuraxle.data_container.DataContainer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; Tuple[neuraxle.pipeline.Pipeline, neuraxle.data_container.DataContainer]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L627"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline.fit_transform_data_container" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit transform sequentially if any step is fittable, such as with <code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchSequentialPipeline</span></code>. Otherwise transform in parallel as it should.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_container</strong> (<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><em>DataContainer</em></a>) – data container</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><em>ExecutionContext</em></a>) – execution context</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline.transform_data_container">
<code class="descname">transform_data_container</code><span class="sig-paren">(</span><em>data_container: neuraxle.data_container.DataContainer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.data_container.DataContainer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L654"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline.transform_data_container" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform data container</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataContainer</span></code></a></p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>data_container</strong> (<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><em>DataContainer</em></a>) – data container to transform.</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><em>ExecutionContext</em></a>) – execution context</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>data container</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._did_transform">
<code class="descname">_did_transform</code><span class="sig-paren">(</span><em>data_container: neuraxle.data_container.DataContainer</em>, <em>context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.data_container.DataContainer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L712"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._did_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Stop all of the workers after transform. Also, join the data using self.data_joiner.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_container</strong> (<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><em>DataContainer</em></a>) – data container</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><em>ExecutionContext</em></a>) – execution context</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>data container</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer">DataContainer</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._did_process">
<code class="descname">_did_process</code><span class="sig-paren">(</span><em>data_container: neuraxle.data_container.DataContainer[~IDT, ~DIT, typing.Union[~EOT, NoneType]][IDT, DIT, Optional[EOT]], context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.data_container.DataContainer[~IDT, ~DIT, typing.Union[~EOT, NoneType]][IDT, DIT, Optional[EOT]]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L729"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._did_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply side effects after any step method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_container</strong> – data container</p></li>
<li><p><strong>context</strong> (<a class="reference internal" href="../neuraxle.base.html#neuraxle.base.ExecutionContext" title="neuraxle.base.ExecutionContext"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExecutionContext</span></code></a>) – execution context</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(data container, execution context)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline.get_n_workers_to_join">
<code class="descname">get_n_workers_to_join</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L733"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline.get_n_workers_to_join" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the total number of terminal steps at the end of each row of queued workers.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._connect_queued_pipeline">
<code class="descname">_connect_queued_pipeline</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L740"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._connect_queued_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Connect all the queued workers together so that the data can flow through each step.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._disconnect_queued_pipeline">
<code class="descname">_disconnect_queued_pipeline</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L752"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._disconnect_queued_pipeline" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._dispatch_minibatch_to_consumer_workers">
<code class="descname">_dispatch_minibatch_to_consumer_workers</code><span class="sig-paren">(</span><em>minibatch_index: int</em>, <em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L761"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._dispatch_minibatch_to_consumer_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Send batches to queued pipeline. It is blocking if there is no more space available in the multiprocessing queues.
Workers might return batches in a different order, but the queue joiner will reorder them at the end.
The queue joiner will use the summary ids to reorder all of the received batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_index</strong> – batch index</p></li>
<li><p><strong>data_container</strong> – data container batch</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming.BaseQueuedPipeline._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming.BaseQueuedPipeline._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.SequentialQueuedPipeline">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">SequentialQueuedPipeline</code><span class="sig-paren">(</span><em>steps: List[Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]], batch_size: int, n_workers_per_step: int = None, max_queued_minibatches: int = None, data_joiner: neuraxle.base.BaseTransformer = None, use_processes: bool = False, use_savers: bool = False, keep_incomplete_batch: bool = True, default_value_data_inputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None, default_value_expected_outputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L775"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="neuraxle.distributed.streaming.BaseQueuedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.BaseQueuedPipeline</span></code></a></p>
<p>Using <code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>, run all steps sequentially even if they are in separate processes or threads.
This is a parallel pipeline that uses a queue to communicate between the steps, and which parallelizes the steps
using many workers in different processes or threads.</p>
<p>This pipeline is useful when the steps are independent of each other and can be run in parallel. This is especially
the case when the steps are not fittable, such as inheriting from the <a class="reference internal" href="../neuraxle.base.html#neuraxle.base.NonFittableMixin" title="neuraxle.base.NonFittableMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">NonFittableMixin</span></code></a>.
Otherwise, fitting may not be parallelized, although the steps can be run in parallel for the transformation.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../neuraxle.pipeline.html#neuraxle.pipeline.BasePipeline" title="neuraxle.pipeline.BasePipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">BasePipeline</span></code></a>,
<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer.minibatches" title="neuraxle.data_container.DataContainer.minibatches"><code class="xref py py-func docutils literal notranslate"><span class="pre">minibatches()</span></code></a>,
<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.StripAbsentValues" title="neuraxle.data_container.StripAbsentValues"><code class="xref py py-class docutils literal notranslate"><span class="pre">StripAbsentValues</span></code></a>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>,
<a class="reference internal" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="neuraxle.distributed.streaming.BaseQueuedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseQueuedPipeline</span></code></a>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelQueuedPipeline</span></code>,</p>
</div>
<dl class="method">
<dt id="neuraxle.distributed.streaming.SequentialQueuedPipeline.get_n_workers_to_join">
<code class="descname">get_n_workers_to_join</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L794"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline.get_n_workers_to_join" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the total number of terminal steps at the end of each row of queued workers.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.SequentialQueuedPipeline._connect_queued_pipeline">
<code class="descname">_connect_queued_pipeline</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L797"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline._connect_queued_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Sequentially connect of the queued workers as producers and consumers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.SequentialQueuedPipeline._dispatch_minibatch_to_consumer_workers">
<code class="descname">_dispatch_minibatch_to_consumer_workers</code><span class="sig-paren">(</span><em>minibatch_index: int</em>, <em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L809"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline._dispatch_minibatch_to_consumer_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Send batches to process to the first queued worker.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_index</strong> – batch index</p></li>
<li><p><strong>data_container</strong> – data container batch</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming.SequentialQueuedPipeline._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">ParallelQueuedFeatureUnion</code><span class="sig-paren">(</span><em>steps: List[Union[neuraxle.base.BaseTransformer, Tuple[int, neuraxle.base.BaseTransformer], Tuple[str, neuraxle.base.BaseTransformer], Tuple[str, int, neuraxle.base.BaseTransformer], Tuple[str, int, int, neuraxle.base.BaseTransformer]]], batch_size: int, n_workers_per_step: int = None, max_queued_minibatches: int = None, data_joiner: neuraxle.base.BaseTransformer = None, use_processes: bool = False, use_savers: bool = False, keep_incomplete_batch: bool = True, default_value_data_inputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None, default_value_expected_outputs: Union[Any, neuraxle.data_container.StripAbsentValues] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L827"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="neuraxle.distributed.streaming.BaseQueuedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming.BaseQueuedPipeline</span></code></a></p>
<p>Using <code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>, run all steps in parallel using QueueWorkers.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">QueueWorker</span></code>,
<a class="reference internal" href="#neuraxle.distributed.streaming.BaseQueuedPipeline" title="neuraxle.distributed.streaming.BaseQueuedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseQueuedPipeline</span></code></a>,
<a class="reference internal" href="#neuraxle.distributed.streaming.SequentialQueuedPipeline" title="neuraxle.distributed.streaming.SequentialQueuedPipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequentialQueuedPipeline</span></code></a>,</p>
</div>
<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion.get_n_workers_to_join">
<code class="descname">get_n_workers_to_join</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L837"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion.get_n_workers_to_join" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the total number of terminal steps at the end of each row of queued workers.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._connect_queued_pipeline">
<code class="descname">_connect_queued_pipeline</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L841"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._connect_queued_pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Connect the queue joiner to all of the queued workers to process data in parallel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._dispatch_minibatch_to_consumer_workers">
<code class="descname">_dispatch_minibatch_to_consumer_workers</code><span class="sig-paren">(</span><em>minibatch_index: int</em>, <em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L854"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._dispatch_minibatch_to_consumer_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>In the case of the feature union, sending a batch to the workers is done by sending the batch
to each of the workers that will work in parallel to consume the same copy sent to all.</p>
</dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming.ParallelQueuedFeatureUnion._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="neuraxle.distributed.streaming.WorkersJoiner">
<em class="property">class </em><code class="descclassname">neuraxle.distributed.streaming.</code><code class="descname">WorkersJoiner</code><span class="sig-paren">(</span><em>batch_size: int</em>, <em>n_worker_wrappers_to_join: int = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L876"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="neuraxle.distributed.streaming._ProducerConsumerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.distributed.streaming._ProducerConsumerMixin</span></code></a>, <a class="reference internal" href="../neuraxle.pipeline.html#neuraxle.pipeline.Joiner" title="neuraxle.pipeline.Joiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">neuraxle.pipeline.Joiner</span></code></a></p>
<p>Consume the results of the other <a class="reference internal" href="#neuraxle.distributed.streaming._ProducerConsumerMixin" title="neuraxle.distributed.streaming._ProducerConsumerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">_ProducerConsumerMixin</span></code></a> workers to join their data.
Also do error handling.</p>
<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>batch_size: int</em>, <em>n_worker_wrappers_to_join: int = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L882"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The Joiner step joins the transformed mini batches together with DACT.minibatches and then DACT.extend method.
Note that the default value for IDs is None.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataContainer</span></code></a>,
<a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer.minibatches" title="neuraxle.data_container.DataContainer.minibatches"><code class="xref py py-func docutils literal notranslate"><span class="pre">minibatches()</span></code></a></p>
</div>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner._setup">
<code class="descname">_setup</code><span class="sig-paren">(</span><em>context: Optional[neuraxle.base.ExecutionContext] = None</em><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L890"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner._setup" title="Permalink to this definition">¶</a></dt>
<dd><p>Internal method to setup the step. May be used by <a class="reference internal" href="../neuraxle.pipeline.html#neuraxle.pipeline.Pipeline" title="neuraxle.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>
to setup the pipeline progressively instead of all at once.</p>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner._teardown">
<code class="descname">_teardown</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[neuraxle.hyperparams.space.RecursiveDict]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L894"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner._teardown" title="Permalink to this definition">¶</a></dt>
<dd><p>Properly clean queue, summary ids, and results during teardown.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>teardowned self</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner.set_join_quantities">
<code class="descname">set_join_quantities</code><span class="sig-paren">(</span><em>n_workers: int</em>, <em>n_minibatches_per_worker: int</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L905"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner.set_join_quantities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner.append_terminal_summary">
<code class="descname">append_terminal_summary</code><span class="sig-paren">(</span><em>name: str</em>, <em>task: neuraxle.distributed.streaming.QueuedMinibatchTask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L911"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner.append_terminal_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Append the summary id of the worker to the list of summaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<code class="docutils literal notranslate"><span class="pre">str</span></code>) – name of the worker</p></li>
<li><p><strong>task</strong> (<a class="reference internal" href="#neuraxle.distributed.streaming.QueuedMinibatchTask" title="neuraxle.distributed.streaming.QueuedMinibatchTask"><code class="xref py py-class docutils literal notranslate"><span class="pre">QueuedMinibatchTask</span></code></a>) – task</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner.join_workers">
<code class="descname">join_workers</code><span class="sig-paren">(</span><em>original_dact: neuraxle.data_container.DataContainer</em>, <em>sync_context: neuraxle.base.ExecutionContext</em><span class="sig-paren">)</span> &#x2192; neuraxle.data_container.DataContainer<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L922"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner.join_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the accumulated results of the workers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>transformed data container</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="../neuraxle.data_container.html#neuraxle.data_container.DataContainer" title="neuraxle.data_container.DataContainer">DataContainer</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner._consume_enqueued_minibatches">
<code class="descname">_consume_enqueued_minibatches</code><span class="sig-paren">(</span><em>sync_context</em><span class="sig-paren">)</span> &#x2192; Dict[str, neuraxle.data_container.ListDataContainer[typing.List[str], neuraxle.data_container.ListDataContainer[~IDT, ~DIT, ~EOT], typing.List[NoneType]][List[str], neuraxle.data_container.ListDataContainer[~IDT, ~DIT, ~EOT][IDT, DIT, EOT], List[None]]]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L947"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner._consume_enqueued_minibatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="neuraxle.distributed.streaming.WorkersJoiner._merge_minibatches">
<code class="descname">_merge_minibatches</code><span class="sig-paren">(</span><em>step_to_minibatches_dacts: Dict[str, neuraxle.data_container.ListDataContainer[typing.List[str], neuraxle.data_container.ListDataContainer[~IDT, ~DIT, ~EOT], typing.List[NoneType]][List[str], neuraxle.data_container.ListDataContainer[~IDT, ~DIT, ~EOT][IDT, DIT, EOT], List[None]]]</em><span class="sig-paren">)</span> &#x2192; List[neuraxle.data_container.ListDataContainer]<a class="reference external" href="https://github.com/Neuraxio/Neuraxle/blob/c355500/neuraxle/distributed/streaming.py#L977"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner._merge_minibatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="neuraxle.distributed.streaming.WorkersJoiner._abc_impl">
<code class="descname">_abc_impl</code><em class="property"> = &lt;_abc_data object&gt;</em><a class="headerlink" href="#neuraxle.distributed.streaming.WorkersJoiner._abc_impl" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../logging/neuraxle.logging.logging.html" class="btn btn-neutral float-right" title="neuraxle.logging.logging" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../metaopt/hyperopt/neuraxle.metaopt.hyperopt.tpe.html" class="btn btn-neutral float-left" title="neuraxle.metaopt.hyperopt.tpe" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p style="float:left;">
        &copy; Copyright 2021 The Neuraxle Authors. All rights reserved. Apache License, Version 2.0.

    </p>

    <p style="float:right;">
      <a href="https://www.neuraxio.com/policies/privacy-policy">Privacy Policy</a>
    </p>

  </div>
   




</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-139527241-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>